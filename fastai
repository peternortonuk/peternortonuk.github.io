https://github.com/fastai/fastbook/blob/master/01_intro.ipynb
# Your Deep Learning Journey
## The Software: PyTorch, fastai, and Jupyter
PyTorch works best as a low-level foundation library, providing the basic operations for higher-level functionality. The fastai library is the most popular library for adding this higher-level functionality on top of PyTorch.

## Running Your First Notebook
There are two folders containing different versions of the notebooks.  
The full folder contains the exact notebooks used to create the book you're reading now, with all the prose and outputs.  
The stripped version has the same headings and code cells, but all outputs and prose have been removed.

**error rate** is the proportion of images that were incorrectly identified

## How Our Image Recognizer Works
```
dls = ImageDataLoaders.from_name_func(
    path, get_image_files(path), valid_pct=0.2, seed=42,
    label_func=is_cat, item_tfms=Resize(224))
```
Define the Transforms that we need. There are two kinds: 
1.   item_tfms are applied to each item
2.   batch_tfms are applied to a batch of items at a time using the GPU, so they're particularly fast

###Split the data:  
**validation set**: valid_pct=0.2 tells fastai to hold out 20% of the data and use it to measure the accuracy of the model  
**training set**: the remaining 80% is used for training
  
###Metrics:  
**error_rate** = percentage of images in the validation set are being classified incorrectly.  
**accuracy** = (1.0 - error_rate)  
**loss** is a "measure of performance" that the training system can use to update weights automatically
  
### Pretrained models
cnn_learner sets the weights in your model to values that have already been trained to recognize a thousand different categories across 1.3 million photos (using the famous ImageNet dataset). A model that has weights that have already been trained on some other dataset is called a pretrained model
#  
When using a pretrained model, cnn_learner will remove the last layer, since that is always specifically customized to the original training task (i.e. ImageNet dataset classification), and replace it with one or more new layers with randomized weights, of an appropriate size for the dataset you are working with. This last part of the model is known as the **head**.
#  
Using a pretrained model for a task different to what it was originally trained for is known as **transfer learning**. 
#  
**Fine-tuning**: A transfer learning technique where the parameters of a pretrained model are updated by training for additional epochs using a different task to that used for pretraining.

##What Our Image Recognizer Learned
